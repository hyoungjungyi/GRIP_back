#!/usr/bin/env python3
"""
Enhanced Guitar MIDI Conversion with Superior Musical Quality
Optimized for natural guitar sound and musical expression
"""

import sys
import os
import pretty_midi
import numpy as np
import librosa
from basic_pitch.inference import predict_and_save
from basic_pitch import ICASSP_2022_MODEL_PATH
import tempfile
import random
import math

def convert_audio_to_midi_enhanced(audio_file_path, output_midi_path):
    """
    Convert audio to MIDI with enhanced musical quality and guitar optimization
    """
    try:
        print(f"Converting {audio_file_path} to enhanced musical MIDI...")
        
        # Create temporary directory for basic-pitch output
        with tempfile.TemporaryDirectory() as temp_dir:
            # Use basic-pitch for initial conversion
            predict_and_save(
                [audio_file_path],
                temp_dir,
                save_midi=True,
                sonify_midi=False,
                save_model_outputs=False,
                save_notes=False,
                model_path=ICASSP_2022_MODEL_PATH,
                midi_tempo=120  # Set standard tempo
            )
            
            # Find the generated MIDI file
            midi_files = [f for f in os.listdir(temp_dir) if f.endswith('.mid')]
            if not midi_files:
                raise Exception("No MIDI file generated by basic-pitch")
            
            temp_midi_path = os.path.join(temp_dir, midi_files[0])
            
            # Load and enhance the MIDI
            midi_data = pretty_midi.PrettyMIDI(temp_midi_path)
            enhanced_midi = enhance_musical_quality(midi_data)
            
            # Save the enhanced MIDI
            enhanced_midi.write(output_midi_path)
            
        print(f"Enhanced MIDI conversion completed: {output_midi_path}")
        return True
        
    except Exception as e:
        print(f"Error converting audio to enhanced MIDI: {str(e)}")
        return False

def enhance_musical_quality(midi_data):
    """
    Enhance the musical quality with advanced musical intelligence
    """
    # Create a new MIDI file with guitar-specific settings
    new_midi = pretty_midi.PrettyMIDI()
    guitar_program = 25  # Acoustic Guitar (steel) - warmer, more natural sound
    
    # Extract and analyze all notes
    all_notes = []
    for instrument in midi_data.instruments:
        for note in instrument.notes:
            all_notes.append(note)
    
    if not all_notes:
        return midi_data
    
    # Sort notes by start time
    all_notes.sort(key=lambda x: x.start)
    
    # Create new guitar instrument
    guitar = pretty_midi.Instrument(program=guitar_program)
    
    # Apply musical intelligence processing
    processed_notes = apply_musical_intelligence(all_notes)
    
    # Apply guitar-specific optimizations
    guitar_optimized_notes = optimize_for_guitar(processed_notes)
    
    # Apply musical expression and phrasing
    final_notes = apply_musical_expression(guitar_optimized_notes)
    
    guitar.notes = final_notes
    new_midi.instruments.append(guitar)
    
    return new_midi

def apply_musical_intelligence(all_notes):
    """
    Apply advanced musical intelligence for melody extraction and note selection
    """
    processed_notes = []
    
    # Musical parameters
    time_resolution = 0.02  # 20ms resolution for precise control
    min_note_duration = 0.15  # Minimum 150ms for musical clarity
    max_note_duration = 2.5   # Maximum 2.5s for natural phrasing
    melody_weight = 1.5       # Prefer melodic range notes
    
    # Analyze musical structure
    total_duration = all_notes[-1].end if all_notes else 0
    current_time = 0
    
    # Track musical context
    last_pitch = None
    phrase_start_time = 0
    note_density = calculate_note_density(all_notes)
    
    while current_time < total_duration + 1.0:
        # Find notes active at current time
        active_notes = [n for n in all_notes 
                       if n.start <= current_time < n.end]
        
        if active_notes:
            # Select best note using musical intelligence
            selected_note = select_best_musical_note(
                active_notes, current_time, last_pitch, note_density
            )
            
            if selected_note:
                # Check if we should add this note
                should_add = should_add_note(
                    selected_note, processed_notes, current_time
                )
                
                if should_add:
                    # Create musically enhanced note
                    enhanced_note = create_enhanced_note(
                        selected_note, current_time, processed_notes
                    )
                    
                    processed_notes.append(enhanced_note)
                    last_pitch = enhanced_note.pitch
        
        current_time += time_resolution
    
    return processed_notes

def calculate_note_density(notes):
    """Calculate note density for musical context"""
    if len(notes) < 2:
        return 1.0
    
    total_time = notes[-1].end - notes[0].start
    return len(notes) / total_time if total_time > 0 else 1.0

def select_best_musical_note(active_notes, current_time, last_pitch, note_density):
    """Select the most musically appropriate note"""
    if len(active_notes) == 1:
        return active_notes[0]
    
    # Score each note based on musical criteria
    best_note = None
    best_score = -1
    
    for note in active_notes:
        score = 0
        
        # Pitch range preference (guitar melodic range)
        if 50 <= note.pitch <= 77:  # D3 to F5 - sweet spot for guitar melody
            score += 3
        elif 45 <= note.pitch <= 84:  # A2 to C6 - acceptable range
            score += 2
        else:
            score += 1
        
        # Velocity preference (clear notes)
        if note.velocity > 60:
            score += 2
        elif note.velocity > 40:
            score += 1
        
        # Duration preference (substantial notes)
        duration = note.end - note.start
        if 0.2 <= duration <= 1.5:
            score += 2
        elif duration > 0.1:
            score += 1
        
        # Melodic continuity (prefer smooth motion)
        if last_pitch:
            interval = abs(note.pitch - last_pitch)
            if interval <= 2:  # Step-wise motion
                score += 3
            elif interval <= 5:  # Small leaps
                score += 2
            elif interval <= 12:  # Octave or less
                score += 1
        
        # Note density consideration
        if note_density < 2:  # Sparse music - prefer longer notes
            if duration > 0.5:
                score += 2
        elif note_density > 4:  # Dense music - prefer shorter, clearer notes
            if 0.1 <= duration <= 0.8:
                score += 2
        
        if score > best_score:
            best_score = score
            best_note = note
    
    return best_note

def should_add_note(selected_note, processed_notes, current_time):
    """Determine if a note should be added based on musical logic"""
    if not processed_notes:
        return True
    
    last_note = processed_notes[-1]
    
    # Avoid rapid repetition of same pitch
    if (last_note.pitch == selected_note.pitch and 
        current_time - last_note.start < 0.2):
        # Extend the previous note instead
        last_note.end = max(last_note.end, selected_note.end)
        return False
    
    # Ensure minimum time between different notes
    time_since_last = current_time - last_note.start
    if time_since_last < 0.08:  # 80ms minimum for clarity
        return False
    
    return True

def create_enhanced_note(original_note, start_time, processed_notes):
    """Create a musically enhanced note"""
    # Calculate duration with musical logic
    base_duration = original_note.end - start_time
    duration = max(0.15, min(base_duration, 2.0))  # 150ms to 2s range
    
    # Calculate velocity with musical expression
    velocity = calculate_musical_velocity(original_note, start_time, processed_notes)
    
    # Ensure playable pitch
    pitch = constrain_to_guitar_range(original_note.pitch)
    
    return pretty_midi.Note(
        velocity=velocity,
        pitch=pitch,
        start=start_time,
        end=start_time + duration
    )

def calculate_musical_velocity(original_note, start_time, processed_notes):
    """Calculate musically expressive velocity"""
    base_velocity = min(max(original_note.velocity, 35), 105)  # Musical range
    
    # Add musical dynamics
    if processed_notes:
        # Phrase dynamics - create natural crescendo/diminuendo
        phrase_position = len(processed_notes) % 8  # 8-note phrases
        if phrase_position < 3:  # Building up
            multiplier = 0.85 + (phrase_position * 0.05)
        elif phrase_position < 6:  # Peak
            multiplier = 1.0
        else:  # Winding down
            multiplier = 0.95 - ((phrase_position - 5) * 0.05)
        
        base_velocity = int(base_velocity * multiplier)
    
    # Add subtle variation for natural feel
    random.seed(int(start_time * 1000 + original_note.pitch))
    variation = random.randint(-6, 6)
    
    return max(30, min(115, base_velocity + variation))

def constrain_to_guitar_range(pitch):
    """Constrain pitch to playable guitar range"""
    # Standard guitar range: E2 (40) to high E on 24th fret (~88)
    # But we'll use a more conservative range for better playability
    min_pitch = 40  # E2 (low E string)
    max_pitch = 81  # A5 (high E string, 17th fret)
    
    if pitch < min_pitch:
        # Transpose up by octaves
        while pitch < min_pitch:
            pitch += 12
    elif pitch > max_pitch:
        # Transpose down by octaves
        while pitch > max_pitch:
            pitch -= 12
    
    return pitch

def optimize_for_guitar(notes):
    """Apply guitar-specific optimizations"""
    if not notes:
        return notes
    
    optimized = []
    
    for i, note in enumerate(notes):
        # Ensure note is in guitar range
        if not (40 <= note.pitch <= 84):
            continue
        
        # Fix timing issues
        if i > 0:
            prev_note = optimized[-1]
            
            # Prevent overlaps
            if note.start < prev_note.end:
                if note.start - prev_note.start < 0.15:
                    # Very close - extend previous note
                    prev_note.end = max(prev_note.end, note.end)
                    continue
                else:
                    # Adjust previous note end
                    prev_note.end = note.start - 0.01
            
            # Add natural phrasing gaps
            gap = note.start - prev_note.end
            if 1.0 < gap < 2.0:  # Natural phrase break
                note.start = prev_note.end + 0.2  # Consistent phrase gap
                note.end += 0.2
        
        # Ensure musical durations
        duration = note.end - note.start
        if duration < 0.12:
            note.end = note.start + 0.12
        elif duration > 2.0:
            note.end = note.start + 2.0
        
        optimized.append(note)
    
    return optimized

def apply_musical_expression(notes):
    """Apply final musical expression touches"""
    if not notes:
        return notes
    
    # Add subtle timing humanization
    for i, note in enumerate(notes):
        # Deterministic "humanization" based on note properties
        random.seed(int(note.pitch * 100 + note.start * 1000))
        
        # Very subtle timing adjustment (±8ms max)
        timing_adjust = random.uniform(-0.008, 0.008)
        note.start = max(0, note.start + timing_adjust)
        note.end = max(note.start + 0.1, note.end + timing_adjust)
        
        # Ensure no overlaps after adjustment
        if i > 0 and note.start < notes[i-1].end:
            note.start = notes[i-1].end + 0.005
            note.end = max(note.start + 0.1, note.end)
    
    # Add musical accents on downbeats
    add_musical_accents(notes)
    
    return notes

def add_musical_accents(notes):
    """Add musical accents for better rhythmic feel"""
    if len(notes) < 4:
        return
    
    # Estimate tempo and add accents on strong beats
    avg_note_duration = sum(n.end - n.start for n in notes) / len(notes)
    beat_duration = max(0.5, avg_note_duration * 2)  # Estimate beat length
    
    for i, note in enumerate(notes):
        # Check if this note falls on a strong beat
        beat_position = (note.start % (beat_duration * 4)) / beat_duration
        
        if beat_position < 0.1 or beat_position > 3.9:  # Downbeat
            note.velocity = min(115, int(note.velocity * 1.15))
        elif abs(beat_position - 2) < 0.1:  # Beat 3 (secondary accent)
            note.velocity = min(110, int(note.velocity * 1.08))

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python midi_conversion_enhanced_musical.py <input_audio> <output_midi>")
        sys.exit(1)
    
    input_audio = sys.argv[1]
    output_midi = sys.argv[2]
    
    if not os.path.exists(input_audio):
        print(f"Error: Input audio file not found: {input_audio}")
        sys.exit(1)
    
    success = convert_audio_to_midi_enhanced(input_audio, output_midi)
    if success:
        print(f"Enhanced musical MIDI conversion successful!")
        sys.exit(0)
    else:
        print("Enhanced musical MIDI conversion failed!")
        sys.exit(1)
