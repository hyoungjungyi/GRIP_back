#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import torch
import torchaudio
import numpy as np
import librosa
import soundfile as sf
from demucs.pretrained import get_model
from demucs.apply import apply_model
import sys

def separate_guitar_enhanced(input_path, output_path):
    try:
        print("ğŸ¸ í–¥ìƒëœ ê¸°íƒ€ ë¶„ë¦¬ ì‹œì‘...")
        
        # ë” ì •í™•í•œ ëª¨ë¸ ì‚¬ìš©
        model_name = "htdemucs"  # High-quality ëª¨ë¸
        model = get_model(model_name)
        model.eval()
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        print(f"ğŸ“± ì‚¬ìš© ì¥ì¹˜: {device}")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ (ë†’ì€ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ìœ ì§€)
        waveform, sr = torchaudio.load(input_path)
        print(f"ğŸ“Š ì›ë³¸ ì˜¤ë””ì˜¤ í˜•íƒœ: {waveform.shape}, ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr}")
        
        # ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜
        if waveform.shape[0] == 1:
            waveform = waveform.repeat(2, 1)
            print("ğŸ”„ ëª¨ë…¸ì—ì„œ ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜")
        
        # Demucs ì ìš© (ë” ë†’ì€ í’ˆì§ˆ ì„¤ì •)
        waveform_tensor = waveform.unsqueeze(0).to(device)
        with torch.no_grad():
            sources = apply_model(model, waveform_tensor, split=True, overlap=0.25)
        
        drums, bass, other, vocals = sources[0].cpu().numpy()
        print("âœ… Demucs ìŠ¤í…œ ë¶„ë¦¬ ì™„ë£Œ")
        
        # ê¸°íƒ€ ì „ìš© í›„ì²˜ë¦¬
        guitar_audio = extract_guitar_only(drums, bass, other, vocals, sr)
        
        # ì €ì¥
        sf.write(output_path, guitar_audio.T, sr, format='WAV', subtype='PCM_16')
        print(f"âœ… í–¥ìƒëœ ê¸°íƒ€ íŒŒì¼ ì €ì¥: {output_path}")
        print(f"ğŸ“Š ìµœì¢… ê¸°íƒ€ ì˜¤ë””ì˜¤ í˜•íƒœ: {guitar_audio.shape}")
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        sys.exit(1)

def extract_guitar_only(drums, bass, other, vocals, sr):
    """ê¸°íƒ€ë§Œ ë³´ìˆ˜ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ë©œë¡œë”” ë³´ì¡´ ìš°ì„ )"""
    print("ğŸ¯ ë³´ìˆ˜ì  ê¸°íƒ€ ì¶”ì¶œ ì‹œì‘...")
    
    # 1. ê¸°ë³¸ì ìœ¼ë¡œ 'other' ìŠ¤í…œ ì‚¬ìš© (ê¸°íƒ€ê°€ ì£¼ë¡œ í¬í•¨ë¨)
    guitar_base = other.copy()
    print("ğŸ“‹ ê¸°ë³¸ 'other' ìŠ¤í…œ ì‚¬ìš©")
    
    # 2. ëª…ë°±í•œ ë² ì´ìŠ¤ ì£¼íŒŒìˆ˜ë§Œ ì œê±° (ë§¤ìš° ë³´ìˆ˜ì )
    print("ğŸ”Š ê·¹ì €ì£¼íŒŒ ì œê±° ì¤‘...")
    for channel in range(guitar_base.shape[0]):
        # 50Hz ì´í•˜ë§Œ ì œê±° (ë² ì´ìŠ¤ ê¸°ë³¸ìŒë§Œ)
        stft = librosa.stft(guitar_base[channel], n_fft=2048, hop_length=512)
        freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)
        
        # ê·¹ì €ì£¼íŒŒë§Œ ì œê±°
        very_low_freq_mask = freqs < 50
        stft[very_low_freq_mask] *= 0.1
        
        # ì—­ë³€í™˜ (ê¸¸ì´ ë§ì¶¤)
        reconstructed = librosa.istft(stft, hop_length=512, length=guitar_base[channel].shape[0])
        guitar_base[channel] = reconstructed
    
    # 3. ê·¹ë‹¨ì ì¸ ë“œëŸ¼ íƒ€ê²©ìŒë§Œ ì œê±° (ë³´ìˆ˜ì )
    print("ğŸ¥ ê·¹ë‹¨ì  íƒ€ê²©ìŒë§Œ ì œê±°...")
    for channel in range(guitar_base.shape[0]):
        # ë§¤ìš° ì•½í•œ HPF ì ìš©
        harmonic, percussive = librosa.effects.hpss(guitar_base[channel], margin=1.0)
        # 80% í•˜ëª¨ë‹‰ + 20% í¼ì»¤ì‹œë¸Œ (ë„ˆë¬´ ê³¼í•˜ê²Œ ì œê±°í•˜ì§€ ì•ŠìŒ)
        guitar_base[channel] = harmonic * 0.8 + percussive * 0.2
    
    # 4. ë§¤ìš° ì•½í•œ ë³´ì»¬ ì œê±°
    print("ğŸ¤ ì•½ê°„ì˜ ë³´ì»¬ ì œê±°...")
    vocals_reduced = vocals * 0.1  # ì•„ì£¼ ì•½í•˜ê²Œë§Œ ë¹¼ê¸°
    guitar_final = guitar_base - vocals_reduced
    
    # 5. ìµœì†Œí•œì˜ ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ë§Œ ì ìš©
    print("ğŸ›ï¸ ìµœì†Œí•œì˜ ë…¸ì´ì¦ˆ ì œê±°...")
    for channel in range(guitar_final.shape[0]):
        audio = guitar_final[channel]
        
        # ë§¤ìš° ë‚®ì€ ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ (ìµœëŒ€ê°’ì˜ 0.5%ë§Œ)
        threshold = np.max(np.abs(audio)) * 0.005
        audio = np.where(np.abs(audio) < threshold, audio * 0.1, audio)
        
        guitar_final[channel] = audio
    
    print("âœ… ë³´ìˆ˜ì  ê¸°íƒ€ ì¶”ì¶œ ì™„ë£Œ")
    return guitar_final

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ì‚¬ìš©ë²•: python guitar_separation_improved.py <input.wav> <output.wav>")
        sys.exit(1)
    
    input_path = sys.argv[1]
    output_path = sys.argv[2]
    separate_guitar_enhanced(input_path, output_path)
